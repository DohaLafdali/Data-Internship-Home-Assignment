{
  "job": {
    "title": "(USA) Senior Data Engineer",
    "industry": "Information Technology and Services,Retail,Financial Services",
    "description": "ltstronggtltugtposition summary what youll doltbrgtltbrgtltugtltstronggtsenior data engineerltbrgtltulgtltligtdata strategy understands articulates and applies principles of the defined strategy to routine business problems that involve a single functionltligtltligtdata transformation and integration extracts data from identified databases creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques develops knowledge of current data science and analytics trendsltligtltligtdata source identification supports the understanding of the priority order of requirements and service level agreements helps identify the most suitable source for data that is fit for purpose performs initial data quality checks on extracted dataltligtltligtdata modeling analyzes complex data elements systems data flows dependencies and relationships to contribute to conceptual physical and logical data models develops the logical data model and physical data models including data warehouse and data mart designs defines relational tables primary and foreign keys and stored procedures to create a data model structure evaluates existing data models and physical databases for variances and discrepancies develops efficient data flows analyzes datarelated system integration challenges and proposes appropriate solutionsltligtltligtcreates training documentation and trains endusers on data modeling oversees the tasks of less experienced programmers and stipulates system troubleshooting supportsltligtltligtcode development and testing writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business technical and data requirements creates test cases to review and validate the proposed solution design creates proofs of concept tests the code using the appropriate testing approach deploys software to production servers contributes code documentation maintains playbooks and provides timely progress updatesltligtltligtproblem formulation translates business problems within ones discipline to data related or mathematical solutions identifies what methods for example analytics big data analytics automation would provide a solution for the problem shares use cases and gives examples to demonstrate how the method would solve the business problemltligtltligtapplied business acumen provides recommendations to business stakeholders to solve complex business issues develops business cases for projects with a projected return on investment or cost savings translates business requirements into projects activities and tasks and aligns to overall business strategy serves as an interpreter and conduit to connect business needs with tangible solutions and results recommends new processes and ways of workingltligtltligtdata governance establishes modifies and documents data governance projects and recommendations implements data governance practices in partnership with business stakeholders and peers interprets company and regulatory policies on data educates others on data governance processes practices policies and guidelines provides recommendations on needed updates or inputs into data governance policies practices or guidelinesltligtltligtdemonstrates uptodate expertise and applies this to the development execution and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationalesltligtltligtprovides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders identifying business needs determining and carrying out necessary processes and practices monitoring progress and results recognizing and capitalizing on improvement opportunities and adapting to competing demands organizational changes and new responsibilitiesltligtltligtmodels compliance with company policies and procedures and supports company mission values and standards of ethics and integrity by incorporating these into the development and implementation of business plans using the open door policy and demonstrating and assisting others with how to apply these in executing business processes and practicesltbrgtltligtltulgtltstronggtltugtwhat youll doltbrgtltugtltstronggtltulgtltligtdirect root cause analysis of critical business and production issues ltligtltligtlead and direct largescale complex crossfunctional projects ltligtltligtbe a technical lead and drive the team towards building a highly scalable and performing container platform ltligtltligtbring new ideas for product enhancement ltligtltligtpromote and support company policies procedures mission values and standards of ethics and integrityltligtltligthelp to define the data engineer strategyltligtltligtability to learn and adapt new technologies passion for continuous improvement ltligtltligtinteract and work with multiple cross functional teamsltbrgtltligtltulgtltstronggtltugtwhat you need to be successful in the roleltbrgtltugtltstronggtltulgtltligta multiskilled sap hana professional with good technofunctional expertise extensive practical knowledge of sap gl and purchasing modules and worked greatly in hana bw on hana bods interfaces ampamp s hanaltligtltligtprior data engineering experience at a startup or mid to large sized corp ltligtltligtproficient oral and written communication skills ltligtltligtprior experience developing or working with hands on experience building running and deploying application with cloud technologies such as microsoft azure google cloud platform ltligtltligtprior experience developing or working with cicd or gitops systems is highly desired ltligtltligtability to learn and adapt new technologies passion for continuous improvement ltligtltligtexposure to continuous build and continuous integration tools ltligtltligtability to deliver in agile method kanban or scrum ltligtltligtexperience consuming rest apis ltligtltligtexperience developing containerized cloud applications ltligtltligtdata engineering database engineering business intelligence or business analytics etl tools and working with large data sets in the cloud ltligtltligtdata modeling analyzes complex data elements systems data flows dependencies and relationships to contribute to conceptual physical and logical data models ltligtltligtdevelops the logical data model and physical data models including data warehouse and data mart designs defines relational tables primary and foreign keys and stored procedures to create a data model structure ltligtltligtarchitectural design develop implement and tune distributed data processing pipelines that process large volume of data focusing on scalability low latency and faulttolerance in every system built ltligtltligtdemonstrates expertise in writing complex highlyoptimized queries across large data sets to write data pipelines and data processing layers ltligtltligtproven working expertise with big data technologies hadoop hdfs hive spark scalapyspark and sql ltligtltligtknowledge and experience in kafka storm druid and presto with handson experience of spark and knowledge of cloud systems are added advantageltbrgtltligtltulgtltstronggtltugtwed love to seeltbrgtltugtltstronggtltulgtltligtexcellent understanding of designing and building scalable high availability distributed multitiered and concurrent applications ltligtltligtexpertise with rdbms oracle sql server mysql with excellent understanding of transaction management and performance tuning ltligtltligtsap hana sap bw and s previous experienceltligtltligtexperience with distributed databases like cassandra cosmos mongodb excellent understanding of nonsql databasesltligtltligtexperience using messaging systems like kafka activemq solid understanding of enterprise service patterns ltbrgtltligtltulgtltstronggtltugtminimal qualificationltbrgtltugtltstronggtltulgtltligtbachelors degree in computer science and years experience in data engineering or related fieldltligtltligt years experience in data engineering or related fieldltligtltligtmasters degree in computer science and years experience in data engineering or related fieldltligtltulgt minimum qualificationsltbrgtltbrgtltemgtltemgtoutlined below are the required minimum qualifications for this position if none are listed there are no minimum qualifications ltbrgtltbrgtltemgtltemgtoption bachelors degree in computer science and years experience in software engineering or related field option years experience inltbrgtltbrgtsoftware engineering or related field option masters degree in computer science and years experience in software engineering or relatedltbrgtltbrgtfieldltbrgtltbrgt years experience in data engineering database engineering business intelligence or business analytics preferred qualificationsltbrgtltbrgtltemgtltemgtoutlined below are the optional preferred qualifications for this position if none are listed there are no preferred qualifications ltbrgtltbrgtltemgtltemgtdata engineering database engineering business intelligence or business analytics etl tools and working with large data sets in the cloud masters degree in computer science or related field and years experience in software engineering primary location se moberly ln bentonville ar united states of america",
    "employment_type": "FULL_TIME",
    "date_posted": "2021-08-27T05:19:38.000Z"
  },
  "company": {
    "name": "Walmart",
    "link": "https://www.linkedin.com/company/walmart"
  },
  "education": {
    "required_credential": "bachelor degree"
  },
  "experience": {
    "months_of_experience": 60,
    "seniority_level": ""
  },
  "salary": {
    "currency": "",
    "min_value": "",
    "max_value": "",
    "unit": ""
  },
  "location": {
    "country": "US",
    "locality": "Bentonville",
    "region": "AR",
    "postal_code": "72716",
    "street_address": null,
    "latitude": 36.37187,
    "longitude": -94.20272
  }
}